# Creating tests



1. Reference `Lombiq.Tests.UI`. You'll need to add the package corresponding to the browser's driver you want to use to the test project too (despite it being added to `Lombiq.Tests.UI` too, it won't be copied over).
2. For complex and important Orchard-level pages that we re-use in multiple tests we create Atata Page classes, e.g. `OrchardSetupPage`, and instead of recording commands we code them directly, see e.g. `OrchardSetupPageExtensions.Setup()`. Most possibly this is not what you want; instead, you'd create recorded tests like `CommercialEntityTests` in Finitive. So create a class like that with the basics of a test method, but no commands yet.
3. Launch the app and go to a page where the next click would lead to the first page of the tested feature. This is most possibly the homepage or the dashboard, both of which you can easily reach with helpers in the test.
4. Open Selenium IDE, create a new project (it doesn't matter, we won't use it) and inside it create a new test case (again, doesn't matter).
5. Start recording. Now everything you do will be recorded as commands in Selenium IDE. Sometimes it messes up the order but don't worry, you can reorder commands freely.
6. Click through the app and use the feature you want to test as you'd use it normally (or try to break it for negative testing). When you want to check whether something is on a site as it should then right click on the element → Selenium IDE → Assert or Verify and then select the appropriate condition. Assert will make the test fail if there is a mismatch, Verify won't (but you have to determine how to handle it, like write some message to the output; Selenium will just generate the same assertion expressions for them). Do make sure to use these appropriately, since most of the time it's not enough to just click through pages and only fail the test if there's an exception but you need to make sure the page looks like it should (e.g. is what you just saved actually loaded, are you logged in as you should?).
7. Once you're done stop the recording. While still in the command list:
      - Reorder commands if necessary.
      - Make sure that the selectors Selenium used as targets are appropriate (like they are indeed unique, as little fragile and not future-proof if possible). Use CSS selectors when the element can be better pinpointed from the HTML structure, and use XPATH selectors if the content of the element helps to match it (like the text of a link). Don't make the selector depend on a user-facing string if possible (as these can change more frequently). The aim is for the selector to be specific (so it only matches the element we want, even in the future there will be more similar ones, like more such fields on a form) but not be overly tied to the HTML structure. The ID selector (if the ID is indeed unique, as it should be) is the most suitable for this. For links (due to the lack of IDs usually) mostly the link texts (even though they're user-facing).
8. Export the test case to C\# xUnit. You won't need Selenium to generate any comments.
9. Copy the commands to the previously prepared test class.
      - Replace what we do differently:
        - For the simple 1-1 replacements use this in the Notepad++ Replace dialog with "Regular expression" Search Mode: "(FindElements)|(FindElement)|(SendKeys)|(Click\\(\\))|(driver)" for "Find what" and "(?1GetAll)(?2Get)(?3ClickAndFillInWithRetries)(?4ClickReliably\\(context\\))(?5context)" for "Replace with".
        - Note that the generate test does operations on an `IWebDriver` instance. While this is available in our tests you'll mostly use the ambient `UIContext`. So change all `driver` references to `context` (extensions are available for this context to proxy usual driver calls to the driver contained in it and you can also access the driver directly).
        - Replace `FindElement()` calls with Atata's `Get()`, `FindElements()` calls with `GetAll()` (unless it's an existence check on an item, then use `Exists()`. (For more such tricky methods see [the Atata docs](https://github.com/atata-framework/atata-webdriverextras#usage).)
        - Replace `SendKeys()` calls with our `ClickAndFillInWithRetries()`. If there is a `Clear()` or `Click()` call before a `SendText()` call then remove it because `ClickAndFillInWithRetries()` already does these, together with retries if it doesn't succeed.
        - Replace `Click()` calls with `ClickReliably(context)`. This won't fail randomly with certain clicks. however, be sure not to use them on `option` tags as that'll throw an exception.
        - Replace `Assert` calls with Shouldly ones. If any selector would make the command fragile (by e.g. making it depend on the number of elements in a container) then try to work around in C\# instead (like instead of selecting a specific element among multiple ones in a container and checking its text with `ShouldBe()`, check the text of the whole container with `ShouldContain()`).
      - Make use of our helpers that cover some common operations like `driver.LogIn()` (quickly run through the existing tests to see what's available).
      - If the code is interacting with checkboxes on the Orchard admin then be aware that the admin theme hides those to make them prettier. Thus selectors on them will fail. To overcome this you can make them visible again with `MakeAdminCheckboxesVisible()`.
      - Sanity check the commands, remove unneeded ones.
      - If there are a lot of commands then add line breaks between sections, like between groups of a form, different pages, and between the Arrange and Assert sections (though with UI tests every command is an assertion too).
      - Add documentation if something is hard to understand.

Note:

- By default any non-warning entry in the Orchard log, any warning or error in the browser log, and any non-successful HTTP response will fail a test.
- Individual driver operations are retried with a timeout, and failing tests are also retried. While you're developing a test this might not be what you want but rather for the tests to fail as quickly as possible. For this, lower the timeout values in and the try count, see [Configuration](Configuration.md).
- UI tests can be quite computationally demanding since your machine is hammering multiple concurrently running Orchard apps via separate browser processes while also serving them, and on top of this potentially also fetching resources from CDNs and other external services. To prevent tests failing locally simply because the machine is overwhelmed and they time out (or just taking more time than if the resources weren't completely saturated) the number of parallel tests is usually capped at a generally safe level in an xUnit config file in the root of the test project (_xunit.runner.json_). If your PC can handle it then feel free to increase the limit for the duration of local testing (but don't commit these changes).
- E-mails can be sent out to a local SMTP server and the received e-mails checked too, fully automated. For how this works check out `EmailConfirmationTests` in Finitive. Note that it also needs Finitive.Web.
- In case of testing Trumbowyg editors, make sure each editor is placed inside its own uniquely named container so that multiple editors on the same page can be identified separately.
